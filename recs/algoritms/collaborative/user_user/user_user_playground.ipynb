{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "from sortedcontainers import SortedList\n",
    "\n",
    "import os\n",
    "\n",
    "start_path = '../../../data/functional/dict/'\n",
    "# print(os.path.join(start_path))\n",
    "\n",
    "# if not os.path.exists(start_path + 'user_to_book.json') or \\\n",
    "#         not os.path.exists(start_path + 'book_to_user.json') or \\\n",
    "#         not os.path.exists(start_path + 'user_book_to_rating.json') or \\\n",
    "#         not os.path.exists(start_path + 'user_book_to_rating_test.json'):\n",
    "#     import data.dict.preprocess_book_data\n",
    "\n",
    "with open(start_path + 'user_to_book_all.json', 'rb') as f:\n",
    "    user_to_book_all = pickle.load(f)\n",
    "\n",
    "with open(start_path + 'book_to_user_all.json', 'rb') as f:\n",
    "    book_to_user_all = pickle.load(f)\n",
    "\n",
    "with open(start_path + 'user_to_book.json', 'rb') as f:\n",
    "    user_to_book = pickle.load(f)\n",
    "\n",
    "with open(start_path + 'book_to_user.json', 'rb') as f:\n",
    "    book_to_user = pickle.load(f)\n",
    "\n",
    "with open(start_path + 'user_book_to_rating.json', 'rb') as f:\n",
    "    user_book_to_rating = pickle.load(f)\n",
    "\n",
    "with open(start_path + 'user_book_to_rating_test.json', 'rb') as f:\n",
    "    user_book_to_rating_test = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "N = np.max(list(book_to_user_all.keys())) + 1\n",
    "\n",
    "m1 = np.max(list(book_to_user_all.keys()))\n",
    "m2 = np.max([m for (u, m), r in user_book_to_rating_test.items()])\n",
    "M = max(m1, m2) + 1\n",
    "\n",
    "K = 25  # number of neighbors we'd like to consider\n",
    "limit = 3  # number of books users must have in common"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "neighbors = {}\n",
    "averages = {}\n",
    "deviations = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def process_user_outer(user_id):\n",
    "    global averages\n",
    "    global deviations\n",
    "    global neighbors\n",
    "    global limit\n",
    "    global K\n",
    "\n",
    "    books_i = user_to_book[user_id]\n",
    "    books_i_set = set(books_i)\n",
    "\n",
    "    ratings_i = {book: user_book_to_rating[(user_id, book)] for book in books_i}\n",
    "    avg_i = np.mean(list(ratings_i.values()))\n",
    "    dev_i = {book: (rating - avg_i) for book, rating in ratings_i.items()}\n",
    "\n",
    "    averages[user_id] = avg_i\n",
    "    deviations[user_id] = dev_i\n",
    "\n",
    "    sl = SortedList()\n",
    "    for j in user_to_book.keys():\n",
    "        books_j = user_to_book[j]\n",
    "        books_j_set = set(books_j)\n",
    "        common_books = (books_i_set & books_j_set)\n",
    "        if len(common_books) >= limit:\n",
    "            ratings_j = {book: user_book_to_rating[(j, book)] for book in books_j}\n",
    "            avg_j = np.mean(list(ratings_j.values()))\n",
    "            dev_j = {book: (rating - avg_j) for book, rating in ratings_j.items()}\n",
    "\n",
    "            numerator = sum(dev_i[m] * dev_j[m] for m in common_books)\n",
    "            sigma_i = np.sqrt(sum(dev_i[m] * dev_i[m] for m in common_books))\n",
    "            sigma_j = np.sqrt(sum(dev_j[m] * dev_j[m] for m in common_books))\n",
    "\n",
    "            w_ij = numerator / (sigma_i * sigma_j)\n",
    "\n",
    "            sl.add((-w_ij, j))\n",
    "            if len(sl) > K:\n",
    "                del sl[-1]\n",
    "\n",
    "    neighbors[user_id] = sl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lr/_klwybj56q90nyw5lnq7mj0h0000gn/T/ipykernel_69413/2957874800.py:32: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  w_ij = numerator / (sigma_i * sigma_j)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process: 11.44%\n"
     ]
    }
   ],
   "source": [
    "keys_len = len(user_to_book.keys())\n",
    "index = 0\n",
    "\n",
    "for i in user_to_book.keys():\n",
    "    global index\n",
    "    global keys_len\n",
    "    index += 1\n",
    "    process_user_outer(i)\n",
    "\n",
    "    if index == 1000:\n",
    "        progress_difference = 0\n",
    "        print(\"process: {:.2f}%\".format(i / keys_len * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def predict(i, m):\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for neg_w, j in neighbors[i]:\n",
    "        try:\n",
    "            numerator += -neg_w * deviations[j][m]\n",
    "            denominator += abs(neg_w)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if denominator == 0:\n",
    "        prediction = averages[i]\n",
    "    else:\n",
    "        prediction = numerator / denominator + averages[i]\n",
    "    prediction = min(10, prediction)\n",
    "    prediction = max(1, prediction)\n",
    "    return prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Середнє значення:  7.899816372828574\n",
      "СКП для сету тренувань: 0.6158051083007932\n",
      "СКП для тестового сету: 3.3679676056804984\n"
     ]
    }
   ],
   "source": [
    "train_predictions = []\n",
    "train_targets = []\n",
    "\n",
    "for (i, b), target in user_book_to_rating.items():\n",
    "    if i in user_to_book.keys() and b in book_to_user.keys():\n",
    "        prediction = predict(i, b)\n",
    "\n",
    "        train_predictions.append(prediction)\n",
    "        train_targets.append(target)\n",
    "\n",
    "print(\"Середнє значення: \", np.mean(train_predictions))\n",
    "\n",
    "test_predictions = []\n",
    "test_targets = []\n",
    "\n",
    "for (i, b), target in user_book_to_rating_test.items():\n",
    "    if i in user_to_book.keys() and b in book_to_user.keys():\n",
    "        prediction = predict(i, b)\n",
    "\n",
    "        test_predictions.append(prediction)\n",
    "        test_targets.append(target)\n",
    "\n",
    "\n",
    "def mse(p, t):\n",
    "    p = np.array(p)\n",
    "    t = np.array(t)\n",
    "    return np.sum((p - t) ** 2) / len(p)\n",
    "\n",
    "\n",
    "print('СКП для сету тренувань:', mse(train_predictions, train_targets))\n",
    "print('СКП для тестового сету:', mse(test_predictions, test_targets))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_info = pd.read_csv('../../../data/edited/books-info-edited.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "book_to_user.keys()\n",
    "\n",
    "sorted_books = {k: v for k, v in sorted(book_to_user.items(), key=lambda item: len(item[1]), reverse=True)}\n",
    "# print(sorted_books)\n",
    "\n",
    "with open('../../../data/shrink/ratings-book-translation.json', 'rb') as f:\n",
    "    ratings_book_translation = pickle.load(f)\n",
    "\n",
    "reversed_translation = {v: k for k, v in ratings_book_translation.items()}\n",
    "\n",
    "sorter = list(sorted_books.keys())\n",
    "sorter = [reversed_translation[i] for i in sorter]\n",
    "sortedIndex = dict(zip(sorter, range(len(sorter))))\n",
    "\n",
    "df_info[\"rank\"] = df_info[\"bookId\"].map(sortedIndex)\n",
    "df_info.sort_values([\"rank\"])[df_info.title.str.contains(\"Potter\")]\n",
    "# df_info.sort_values([\"rank\"])[df_info.title.str.contains(\"Potter\") == True]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "MY_ID = 300000\n",
    "\n",
    "user_to_book[MY_ID] = [ratings_book_translation[i] for i in [81958, 234002, 47570]]\n",
    "\n",
    "for item in user_to_book[MY_ID]:\n",
    "    book_to_user[item].append(MY_ID)\n",
    "    user_book_to_rating[(MY_ID, item)] = randrange(7, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lr/_klwybj56q90nyw5lnq7mj0h0000gn/T/ipykernel_19189/2957874800.py:32: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  w_ij = numerator / (sigma_i * sigma_j)\n"
     ]
    }
   ],
   "source": [
    "process_user_outer(MY_ID)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "data": {
      "text/plain": "             isbn                                              title  \\\n5256   0439139597       Harry Potter and the Goblet of Fire (Book 4)   \n600    0345313860   The Vampire Lestat (Vampire Chronicles, Book II)   \n3720   0439136350  Harry Potter and the Prisoner of Azkaban (Book 3)   \n1539   0345339703  The Fellowship of the Ring (The Lord of the Ri...   \n2735   0590353403     Harry Potter and the Sorcerer's Stone (Book 1)   \n...           ...                                                ...   \n7486   0380762595                                      Until Forever   \n6427   0312950489   The Black Echo (Detective Harry Bosch Mysteries)   \n6899   051511264X                                      Prime Witness   \n13401  0671007610                                     Olivia (Logan)   \n24421  055328990X                                       Texas! Chase   \n\n                    author  year           publisher  \\\n5256         J. K. Rowling  2000          Scholastic   \n600              ANNE RICE  1986    Ballantine Books   \n3720         J. K. Rowling  1999          Scholastic   \n1539        J.R.R. TOLKIEN  1986             Del Rey   \n2735         J. K. Rowling  1998          Scholastic   \n...                    ...   ...                 ...   \n7486       Johanna Lindsey  1995                Avon   \n6427      Michael Connelly  1993  St. Martin's Press   \n6899   Steven Paul Martini  1994          Jove Books   \n13401         V.C. Andrews  1999        Pocket Books   \n24421         SANDRA BROWN  1991              Bantam   \n\n                                                 image_s  \\\n5256   http://images.amazon.com/images/P/0439139597.0...   \n600    http://images.amazon.com/images/P/0345313860.0...   \n3720   http://images.amazon.com/images/P/0439136350.0...   \n1539   http://images.amazon.com/images/P/0345339703.0...   \n2735   http://images.amazon.com/images/P/0590353403.0...   \n...                                                  ...   \n7486   http://images.amazon.com/images/P/0380762595.0...   \n6427   http://images.amazon.com/images/P/0312950489.0...   \n6899   http://images.amazon.com/images/P/051511264X.0...   \n13401  http://images.amazon.com/images/P/0671007610.0...   \n24421  http://images.amazon.com/images/P/055328990X.0...   \n\n                                                 image_m  \\\n5256   http://images.amazon.com/images/P/0439139597.0...   \n600    http://images.amazon.com/images/P/0345313860.0...   \n3720   http://images.amazon.com/images/P/0439136350.0...   \n1539   http://images.amazon.com/images/P/0345339703.0...   \n2735   http://images.amazon.com/images/P/0590353403.0...   \n...                                                  ...   \n7486   http://images.amazon.com/images/P/0380762595.0...   \n6427   http://images.amazon.com/images/P/0312950489.0...   \n6899   http://images.amazon.com/images/P/051511264X.0...   \n13401  http://images.amazon.com/images/P/0671007610.0...   \n24421  http://images.amazon.com/images/P/055328990X.0...   \n\n                                                 image_l  bookId    rank  \\\n5256   http://images.amazon.com/images/P/0439139597.0...  177167    34.0   \n600    http://images.amazon.com/images/P/0345313860.0...   17527    37.0   \n3720   http://images.amazon.com/images/P/0439136350.0...  143842    43.0   \n1539   http://images.amazon.com/images/P/0345339703.0...  166721    58.0   \n2735   http://images.amazon.com/images/P/0590353403.0...   31657    62.0   \n...                                                  ...     ...     ...   \n7486   http://images.amazon.com/images/P/0380762595.0...  157624  1956.0   \n6427   http://images.amazon.com/images/P/0312950489.0...   76710  2757.0   \n6899   http://images.amazon.com/images/P/051511264X.0...   54705  2887.0   \n13401  http://images.amazon.com/images/P/0671007610.0...  111932  3289.0   \n24421  http://images.amazon.com/images/P/055328990X.0...  143637  3893.0   \n\n       rated_rank  \n5256            0  \n600             1  \n3720            2  \n1539            3  \n2735            4  \n...           ...  \n7486           95  \n6427           96  \n6899           97  \n13401          98  \n24421          99  \n\n[100 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isbn</th>\n      <th>title</th>\n      <th>author</th>\n      <th>year</th>\n      <th>publisher</th>\n      <th>image_s</th>\n      <th>image_m</th>\n      <th>image_l</th>\n      <th>bookId</th>\n      <th>rank</th>\n      <th>rated_rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5256</th>\n      <td>0439139597</td>\n      <td>Harry Potter and the Goblet of Fire (Book 4)</td>\n      <td>J. K. Rowling</td>\n      <td>2000</td>\n      <td>Scholastic</td>\n      <td>http://images.amazon.com/images/P/0439139597.0...</td>\n      <td>http://images.amazon.com/images/P/0439139597.0...</td>\n      <td>http://images.amazon.com/images/P/0439139597.0...</td>\n      <td>177167</td>\n      <td>34.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>600</th>\n      <td>0345313860</td>\n      <td>The Vampire Lestat (Vampire Chronicles, Book II)</td>\n      <td>ANNE RICE</td>\n      <td>1986</td>\n      <td>Ballantine Books</td>\n      <td>http://images.amazon.com/images/P/0345313860.0...</td>\n      <td>http://images.amazon.com/images/P/0345313860.0...</td>\n      <td>http://images.amazon.com/images/P/0345313860.0...</td>\n      <td>17527</td>\n      <td>37.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3720</th>\n      <td>0439136350</td>\n      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n      <td>J. K. Rowling</td>\n      <td>1999</td>\n      <td>Scholastic</td>\n      <td>http://images.amazon.com/images/P/0439136350.0...</td>\n      <td>http://images.amazon.com/images/P/0439136350.0...</td>\n      <td>http://images.amazon.com/images/P/0439136350.0...</td>\n      <td>143842</td>\n      <td>43.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1539</th>\n      <td>0345339703</td>\n      <td>The Fellowship of the Ring (The Lord of the Ri...</td>\n      <td>J.R.R. TOLKIEN</td>\n      <td>1986</td>\n      <td>Del Rey</td>\n      <td>http://images.amazon.com/images/P/0345339703.0...</td>\n      <td>http://images.amazon.com/images/P/0345339703.0...</td>\n      <td>http://images.amazon.com/images/P/0345339703.0...</td>\n      <td>166721</td>\n      <td>58.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2735</th>\n      <td>0590353403</td>\n      <td>Harry Potter and the Sorcerer's Stone (Book 1)</td>\n      <td>J. K. Rowling</td>\n      <td>1998</td>\n      <td>Scholastic</td>\n      <td>http://images.amazon.com/images/P/0590353403.0...</td>\n      <td>http://images.amazon.com/images/P/0590353403.0...</td>\n      <td>http://images.amazon.com/images/P/0590353403.0...</td>\n      <td>31657</td>\n      <td>62.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7486</th>\n      <td>0380762595</td>\n      <td>Until Forever</td>\n      <td>Johanna Lindsey</td>\n      <td>1995</td>\n      <td>Avon</td>\n      <td>http://images.amazon.com/images/P/0380762595.0...</td>\n      <td>http://images.amazon.com/images/P/0380762595.0...</td>\n      <td>http://images.amazon.com/images/P/0380762595.0...</td>\n      <td>157624</td>\n      <td>1956.0</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>6427</th>\n      <td>0312950489</td>\n      <td>The Black Echo (Detective Harry Bosch Mysteries)</td>\n      <td>Michael Connelly</td>\n      <td>1993</td>\n      <td>St. Martin's Press</td>\n      <td>http://images.amazon.com/images/P/0312950489.0...</td>\n      <td>http://images.amazon.com/images/P/0312950489.0...</td>\n      <td>http://images.amazon.com/images/P/0312950489.0...</td>\n      <td>76710</td>\n      <td>2757.0</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>6899</th>\n      <td>051511264X</td>\n      <td>Prime Witness</td>\n      <td>Steven Paul Martini</td>\n      <td>1994</td>\n      <td>Jove Books</td>\n      <td>http://images.amazon.com/images/P/051511264X.0...</td>\n      <td>http://images.amazon.com/images/P/051511264X.0...</td>\n      <td>http://images.amazon.com/images/P/051511264X.0...</td>\n      <td>54705</td>\n      <td>2887.0</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>13401</th>\n      <td>0671007610</td>\n      <td>Olivia (Logan)</td>\n      <td>V.C. Andrews</td>\n      <td>1999</td>\n      <td>Pocket Books</td>\n      <td>http://images.amazon.com/images/P/0671007610.0...</td>\n      <td>http://images.amazon.com/images/P/0671007610.0...</td>\n      <td>http://images.amazon.com/images/P/0671007610.0...</td>\n      <td>111932</td>\n      <td>3289.0</td>\n      <td>98</td>\n    </tr>\n    <tr>\n      <th>24421</th>\n      <td>055328990X</td>\n      <td>Texas! Chase</td>\n      <td>SANDRA BROWN</td>\n      <td>1991</td>\n      <td>Bantam</td>\n      <td>http://images.amazon.com/images/P/055328990X.0...</td>\n      <td>http://images.amazon.com/images/P/055328990X.0...</td>\n      <td>http://images.amazon.com/images/P/055328990X.0...</td>\n      <td>143637</td>\n      <td>3893.0</td>\n      <td>99</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_books = {}\n",
    "for item in sorted_books.keys():\n",
    "    if item not in user_to_book[MY_ID]:\n",
    "        predicted_books[item] = predict(MY_ID, item)\n",
    "\n",
    "\n",
    "predicted_books_sorted = [reversed_translation[k] for k, v in sorted(predicted_books.items(), key=lambda item: item[1], reverse=True)][:100]\n",
    "predicted_books_sorted_kv = {predicted_books_sorted[i]: i for i in range(len(predicted_books_sorted))}\n",
    "\n",
    "predicted_df = df_info[df_info[\"bookId\"].isin(predicted_books_sorted)].copy()\n",
    "predicted_df[\"rated_rank\"] = predicted_df.bookId.map(predicted_books_sorted_kv)\n",
    "\n",
    "final_books = predicted_df.dropna().sort_values([\"rated_rank\"])\n",
    "final_books"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}